device: 0
seed: 2021
log_interval: 300

# DATA
train_data: ../data/preprocessed/train_data.txt
dev_data: ../data/preprocessed/dev_data.txt
output_folder: ../saved_models/
logs: ../logs/

exp_name: 'n2c2'
model_name: 'bert'

# Hyper-parameters
batch_size: 10
epochs: 10
warmup_epochs: 0


dummy_data: False
max_sen_len: 200
hidden_dim: 64 #not really usefull for now
# max_sent_len: 50
enc_dim: 768
enc_layers: 12
input_dropout: 0.3
output_dropout: 0.3
lr: 0.00005
weight_decay: 0.000001
clip: 10
# max_vocab_size: 40000
# cutoff_freq:
# lowercase: True
patience: 5
accumulate_batches: 1

# FLAGS
early_stop: True
# include_positions: True
freeze_pretrained: False
autoscalling: True
