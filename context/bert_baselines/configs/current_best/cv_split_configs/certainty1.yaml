# Experiment
name: clinical_bert/mdl/n2c2_i2b2_certainty/version_2/cv_split_runs/1
description: Bio_ClinicalBERT using entity spans on the Certainty task from n2c2 2022
  and i2b2 2009
logdir: /mnt/iusers01/nactem01/u14498jv/scratch/n2c2_track1/context/bert_baseline_logs/
random_seed: 0

# Data
dataset_name: n2c2Context
data_dir: /mnt/iusers01/nactem01/u14498jv/Projects/n2c2-track1/n2c2Track1TrainingData-v3/cv_splits/1/
sentences_dir: /mnt/iusers01/nactem01/u14498jv/Projects/n2c2-track1/n2c2Track1TrainingData-v3/cv_splits/1/segmented
tasks_to_load:
- Certainty
window_size: 1
max_train_examples: null
auxiliary_data:
  i2b2Event:
    data_dir: /mnt/iusers01/nactem01/u14498jv/Projects/n2c2-track1/auxiliary_data/i2b2_2009/brat/
    dataset_name: i2b2Event
    max_train_examples: null
    sentences_dir: /mnt/iusers01/nactem01/u14498jv/Projects/n2c2-track1/auxiliary_data/i2b2_2009/segmented/
    tasks_to_load:
    - Certainty
    window_size: 0
dataset_sample_strategy: annealed

# Model
model_name: bert-sequence-classifier
bert_model_name_or_path: emilyalsentzer/Bio_ClinicalBERT
freeze_pretrained: false
use_entity_spans: true
entity_pool_fn: first
mark_entities: true
max_seq_length: 300
dropout_prob: 0.2

# Losses
classifier_loss_fn: cross-entropy
classifier_loss_kwargs:
  label_smoothing: 0.0
mask_loss_fn: ratio
mask_loss_kwargs: {}

# Training
batch_size: 32
sample_strategy: null
lr: 3.0e-05
weight_decay: 0.0
gradient_clip_val: 10.0
max_epochs: 20

