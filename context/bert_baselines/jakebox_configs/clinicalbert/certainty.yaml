# Experiment
name: clinical_bert/certainty
description: Bio_ClinicalBERT on the Certainty task only on v3 data
logdir: /home/jav/Documents/Projects/n2c2_2022/n2c2-track1/context/bert_baselines/logs/
random_seed: 0
monitor: avg_macro_f1

# Data
dataset_name: n2c2Context
data_dir: /home/jav/Documents/Projects/n2c2_2022/n2c2-track1/n2c2Track1TrainingData-v3/data_v3/
sentences_dir: /home/jav/Documents/Projects/n2c2_2022/n2c2-track1/n2c2Track1TrainingData-v3/segmented/
tasks_to_load:
- Certainty
window_size: 0
max_train_examples: null
auxiliary_data: {}
dataset_sample_strategy: sequential
dataset_sampler_kwargs: {}

# Model
model_name: bert-sequence-attentions
bert_model_name_or_path: emilyalsentzer/Bio_ClinicalBERT
freeze_pretrained: false
use_entity_spans: true
entity_pool_fn: max
mark_entities: false
entity_markers: ['[unused1]', '[unused2]']
use_levitated_markers: true
levitated_window_size: 5
levitated_marker_pool_fn: attention-sparsegen
levitated_pooler_kwargs: {"lam": -5.0}
levitated_pos_tags: null
levitated_word_list: null
max_seq_length: 256
dropout_prob: 0.1

# Losses
classifier_loss_fn: cross-entropy
classifier_loss_kwargs: {}
mask_loss_fn: ratio
mask_loss_kwargs: {}

# Training
batch_size: 1
sample_strategy: null
lr: 3.0e-05
weight_decay: 0.0
gradient_clip_val: 10.0
max_epochs: 10

